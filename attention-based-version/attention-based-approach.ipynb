{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d249bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 1: IMPORTS & CONFIG\n",
    "# ==============================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------\n",
    "# HYPERPARAMETERS (TUNE HERE)\n",
    "# ------------------------------\n",
    "\n",
    "SEQ_LEN = 20                  # How many previous laps to look at\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LR = 3e-4                     # Learning rate\n",
    "D_MODEL = 128                 # Transformer hidden size\n",
    "NHEAD = 4                     # Attention heads\n",
    "NUM_LAYERS = 3                # Transformer layers\n",
    "DROPOUT = 0.1\n",
    "ALPHA = 1.0                   # Weight for pit loss\n",
    "BETA = 0.5                    # Weight for tire loss\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8802b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 2: LOAD DATA\n",
    "# ==============================\n",
    "\n",
    "data_path = \"/Users/nurulmansibtalukder/Desktop/WAY TO EVERYTHING/BUET_STUFFS/3-2/CSE 330 - Machine Learning Sessional/ML-Project-CSE330---F1-Pitstop-Strategy-Predictor/src/f1_complete_dataset_2020_2024.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 3: FEATURE ENGINEERING\n",
    "# ==============================\n",
    "\n",
    "# Example derived features\n",
    "df[\"degradation\"] = df.groupby([\"race_id\", \"driver_id\"])[\"lap_time\"].diff().fillna(0)\n",
    "\n",
    "df[\"rolling_avg_3\"] = (\n",
    "    df.groupby([\"race_id\", \"driver_id\"])[\"lap_time\"]\n",
    "    .rolling(3)\n",
    "    .mean()\n",
    "    .reset_index(level=[0,1], drop=True)\n",
    ")\n",
    "\n",
    "df[\"rolling_avg_3\"] = df[\"rolling_avg_3\"].fillna(method=\"bfill\")\n",
    "\n",
    "# Undercut flag (example logic)\n",
    "df[\"undercut_flag\"] = (\n",
    "    (df[\"gap_to_front\"] < 3.0) & (df[\"tire_age\"] > 10)\n",
    ").astype(int)\n",
    "\n",
    "# Target\n",
    "df[\"pit_label\"] = df[\"is_pit_lap\"]  # 1 if pit occurred\n",
    "df[\"tire_label\"] = df[\"next_compound\"]  # must be encoded as 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 4: NORMALIZATION\n",
    "# ==============================\n",
    "\n",
    "continuous_cols = [\n",
    "    \"lap_number\",\n",
    "    \"position\",\n",
    "    \"gap_to_leader\",\n",
    "    \"gap_to_front\",\n",
    "    \"gap_to_behind\",\n",
    "    \"lap_time\",\n",
    "    \"sector_1\",\n",
    "    \"sector_2\",\n",
    "    \"sector_3\",\n",
    "    \"track_temp\",\n",
    "    \"tire_age\",\n",
    "    \"degradation\",\n",
    "    \"rolling_avg_3\",\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[continuous_cols] = scaler.fit_transform(df[continuous_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10086e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 5: SEQUENCE CREATION\n",
    "# ==============================\n",
    "\n",
    "def create_sequences(df, seq_len):\n",
    "    sequences = []\n",
    "    \n",
    "    grouped = df.groupby([\"race_id\", \"driver_id\"])\n",
    "    \n",
    "    for (_, _), group in grouped:\n",
    "        group = group.sort_values(\"lap_number\")\n",
    "        \n",
    "        for i in range(len(group) - seq_len):\n",
    "            seq = group.iloc[i:i+seq_len]\n",
    "            target_row = group.iloc[i+seq_len]\n",
    "            \n",
    "            sequences.append({\n",
    "                \"features\": seq,\n",
    "                \"pit_label\": target_row[\"pit_label\"],\n",
    "                \"tire_label\": target_row[\"tire_label\"]\n",
    "            })\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "sequences = create_sequences(df, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 6: DATASET CLASS\n",
    "# ==============================\n",
    "\n",
    "class F1Dataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.sequences[idx]\n",
    "        seq_df = item[\"features\"]\n",
    "        \n",
    "        lap_features = seq_df[continuous_cols + [\"undercut_flag\"]].values\n",
    "        \n",
    "        driver_id = seq_df[\"driver_id\"].iloc[0]\n",
    "        track_id = seq_df[\"track_id\"].iloc[0]\n",
    "        \n",
    "        pit_label = item[\"pit_label\"]\n",
    "        tire_label = item[\"tire_label\"]\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(lap_features, dtype=torch.float32),\n",
    "            torch.tensor(driver_id, dtype=torch.long),\n",
    "            torch.tensor(track_id, dtype=torch.long),\n",
    "            torch.tensor(pit_label, dtype=torch.float32),\n",
    "            torch.tensor(tire_label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "dataset = F1Dataset(sequences)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 7: TRANSFORMER MODEL\n",
    "# ==============================\n",
    "\n",
    "class PitTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_drivers, num_tracks):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embeddings (TUNE DIMENSIONS HERE)\n",
    "        self.driver_emb = nn.Embedding(num_drivers, 8)\n",
    "        self.track_emb = nn.Embedding(num_tracks, 8)\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_dim + 16, D_MODEL)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=D_MODEL,\n",
    "            nhead=NHEAD,\n",
    "            dropout=DROPOUT,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=NUM_LAYERS\n",
    "        )\n",
    "        \n",
    "        # Multi-task heads\n",
    "        self.pit_head = nn.Linear(D_MODEL, 1)\n",
    "        self.tire_head = nn.Linear(D_MODEL, 3)\n",
    "    \n",
    "    def forward(self, x, driver_id, track_id):\n",
    "        driver_emb = self.driver_emb(driver_id)\n",
    "        track_emb = self.track_emb(track_id)\n",
    "        \n",
    "        context = torch.cat([driver_emb, track_emb], dim=1)\n",
    "        context = context.unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        \n",
    "        x = torch.cat([x, context], dim=2)\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        h_t = x[:, -1, :]\n",
    "        \n",
    "        pit_logits = self.pit_head(h_t)\n",
    "        tire_logits = self.tire_head(h_t)\n",
    "        \n",
    "        return pit_logits, tire_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12727882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 8: LOSS FUNCTIONS\n",
    "# ==============================\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        bce = F.binary_cross_entropy_with_logits(logits, targets.unsqueeze(1), reduction='none')\n",
    "        pt = torch.exp(-bce)\n",
    "        loss = ((1 - pt) ** self.gamma) * bce\n",
    "        return loss.mean()\n",
    "\n",
    "pit_loss_fn = FocalLoss(gamma=2)   # TUNE gamma\n",
    "tire_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e95f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 9: TRAINING LOOP\n",
    "# ==============================\n",
    "\n",
    "model = PitTransformer(\n",
    "    input_dim=len(continuous_cols) + 1,\n",
    "    num_drivers=df[\"driver_id\"].nunique(),\n",
    "    num_tracks=df[\"track_id\"].nunique()\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for x, driver_id, track_id, pit_label, tire_label in tqdm(dataloader):\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "        driver_id = driver_id.to(DEVICE)\n",
    "        track_id = track_id.to(DEVICE)\n",
    "        pit_label = pit_label.to(DEVICE)\n",
    "        tire_label = tire_label.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pit_logits, tire_logits = model(x, driver_id, track_id)\n",
    "        \n",
    "        pit_loss = pit_loss_fn(pit_logits, pit_label)\n",
    "        \n",
    "        tire_mask = pit_label == 1\n",
    "        if tire_mask.sum() > 0:\n",
    "            tire_loss = tire_loss_fn(tire_logits[tire_mask], tire_label[tire_mask])\n",
    "        else:\n",
    "            tire_loss = torch.tensor(0.0).to(DEVICE)\n",
    "        \n",
    "        loss = ALPHA * pit_loss + BETA * tire_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 10: EVALUATION\n",
    "# ==============================\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, driver_id, track_id, pit_label, tire_label in dataloader:\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "        driver_id = driver_id.to(DEVICE)\n",
    "        track_id = track_id.to(DEVICE)\n",
    "        \n",
    "        pit_logits, _ = model(x, driver_id, track_id)\n",
    "        probs = torch.sigmoid(pit_logits).cpu().numpy()\n",
    "        \n",
    "        preds = (probs > 0.5).astype(int)\n",
    "        \n",
    "        all_preds.extend(preds.flatten())\n",
    "        all_targets.extend(pit_label.numpy())\n",
    "\n",
    "print(\"F1:\", f1_score(all_targets, all_preds))\n",
    "print(\"Precision:\", precision_score(all_targets, all_preds))\n",
    "print(\"Recall:\", recall_score(all_targets, all_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
